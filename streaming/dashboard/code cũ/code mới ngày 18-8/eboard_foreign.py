import json
import config
from ssi_fc_data.fc_md_stream import MarketDataStream
from ssi_fc_data.fc_md_client import MarketDataClient
from confluent_kafka import Producer
import time
from datetime import datetime, time as dtime, date
import threading
from filtered_stock.active_stocks import active_stocks
import signal
import sys
import logging

# -------------------- Logging setup --------------------
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("stream.log"),
        logging.StreamHandler()
    ])

# -------------------- Globals --------------------
stop_event = threading.Event()
last_msg_time = None
holiday = [date(2026, 1, 1)]

# Kafka Producer t·ªëi ∆∞u batch
producer = Producer({
    'bootstrap.servers':'broker:29092',
    'linger.ms':0,
    'batch.num.messages':1000,
    'queue.buffering.max.kbytes': 32768,
    'compression.type': 'lz4',
    'acks': '1'
})
topic_name = "eboard_foreign"

# -------------------- Shutdown handler --------------------
def shutdown_handler(sig, frame):
    logging.info("üîÑ Shutdown signal received, flushing producer...")
    producer.flush()
    logging.info("‚úÖ Producer flushed. Exiting.")
    sys.exit(0)

signal.signal(signal.SIGINT, shutdown_handler)   # Ctrl+C
signal.signal(signal.SIGTERM, shutdown_handler)  # Docker stop

# -------------------- Trading time check --------------------
def is_trading_time():
    now = datetime.now()
    today = now.date()
    if now.weekday() >= 5 or today in holiday:
        return False

    t9h = dtime(9, 0)
    t12h = dtime(12, 0)
    t13h = dtime(13, 0)
    t15h = dtime(15, 0)

    check = now.time()
    return (t9h <= check <= t12h) or (t13h <= check <= t15h)


# -------------------- Message handler --------------------
def on_message(message):
    global last_msg_time
    try:
        data = message.get('Content', '{}')
        data = json.loads(data)
        symbol=data['Symbol']
        #l·ªçc c·ªï phi·∫øu
        # if symbol not in active_stocks:
        #     return

        result = {
            'function': 'eboard_foreign',
            'content': {
                'symbol': data['Symbol'],
                'buy': data['BuyVol'],
                'sell': data['SellVol'],
                'room': data['CurrentRoom']
            }
        }
        producer.produce(
            topic=topic_name,
            key=symbol,
            value=json.dumps(result)
            )
        producer.poll(0)
        last_msg_time = time.time()

    except Exception as e:
        logging.exception("‚ùó L·ªói gi·∫£i m√£ JSON: ")

# -------------------- Stream error handlers --------------------
def on_error(error):
    logging.error("‚ùó L·ªói: %s", error)
    stop_event.set()

def on_close():
    logging.info("üîí K·∫øt n·ªëi ƒë√£ ƒë√≥ng")
    stop_event.set()

def on_open():
    logging.info("üîì K·∫øt n·ªëi ƒë√£ m·ªü")

# -------------------- Main streaming loop --------------------
def stream():
    global last_msg_time
    while True:
        try:
            stop_event.clear()
            mm = MarketDataStream(config, MarketDataClient(config))
            last_msg_time = time.time()

            mm.start(on_message, on_error, "R:ALL")

            while is_trading_time() and not stop_event.is_set():
                time.sleep(1)
                if time.time() - last_msg_time > 10:
                    logging.warning("‚ö†Ô∏è Kh√¥ng c√≥ data m·ªõi trong 10s, reconnect...")
                    stop_event.set()

        except Exception as e:
            logging.exception("‚ö†Ô∏è L·ªói trong stream():")
        import json
import config
from ssi_fc_data.fc_md_stream import MarketDataStream
from ssi_fc_data.fc_md_client import MarketDataClient
from confluent_kafka import Producer
import time
from datetime import datetime, time as dtime, date
import threading
from filtered_stock.active_stocks import active_stocks
import signal
import sys
import logging

# -------------------- Logging setup --------------------
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("stream.log"),
        logging.StreamHandler()
    ])

# -------------------- Globals --------------------
stop_event = threading.Event()
last_msg_time = None
holiday = [date(2026, 1, 1)]

# Kafka Producer t·ªëi ∆∞u batch
producer = Producer({
    'bootstrap.servers':'broker:29092',
    'linger.ms':5,
    'batch.num.messages':1000,
    'queue.buffering.max.kbytes': 32768,
    'compression.type': 'lz4',
    'acks': '1' 
})
topic_name = "eboard_table"

# -------------------- Shutdown handler --------------------
def shutdown_handler(sig, frame):
    logging.info("üîÑ Shutdown signal received, flushing producer...")
    producer.flush()
    logging.info("‚úÖ Producer flushed. Exiting.")
    sys.exit(0)

signal.signal(signal.SIGINT, shutdown_handler)   # Ctrl+C
signal.signal(signal.SIGTERM, shutdown_handler)  # Docker stop

# -------------------- Trading time check --------------------
def is_trading_time():
    now = datetime.now()
    today = now.date()
    if now.weekday() >= 5 or today in holiday:
        return False

    t9h = dtime(9, 0)
    t12h = dtime(12, 0)
    t13h = dtime(13, 0)
    t15h = dtime(15, 0)

    check = now.time()
    return (t9h <= check <= t12h) or (t13h <= check <= t15h)


# -------------------- Message handler --------------------
def on_message(message):
    global last_msg_time
    try:
        data = message.get('Content', '{}')
        data = json.loads(data)
        symbol=data['Symbol']
        #l·ªçc cp
        # if symbol not in active_stocks:
        #     return

        result={
            'function':'eboard_table',
            'content': {
                'symbol': data['Symbol'],
                'ceiling': data['Ceiling'] / 1000,
                'floor': data['Floor'] / 1000,
                'refPrice': data['RefPrice'] / 1000,
                'buy':{
                    'price': [data['BidPrice1'] / 1000,data['BidPrice2'] / 1000,data['BidPrice3'] / 1000],
                    'vol': [data['BidVol1'] ,data['BidVol2'] ,data['BidVol3'] ]
                },
                'match':{
                    'price': data['LastPrice'] / 1000,
                    'vol': data['LastVol'],
                    'change': data['Change'],
                    'ratioChange': data['RatioChange'],
                },
                'sell':{
                    'price': [data['AskPrice1'] / 1000,data['AskPrice2'] / 1000,data['AskPrice3'] / 1000],
                    'vol': [data['AskVol1'] ,data['AskVol2'] ,data['AskVol3'] ]
                },
                'totalVol': data['TotalVol'],
                'high': data['High'] / 1000,
                'low': data['Low'] / 1000
            }

        }
        
        producer.produce(
            topic=topic_name,
            key=symbol,
            value=json.dumps(result)
            )
        producer.poll(0)
        last_msg_time = time.time()

    except Exception as e:
        logging.exception("‚ùó L·ªói gi·∫£i m√£ JSON: ")

# -------------------- Stream error handlers --------------------
def on_error(error):
    logging.error("‚ùó L·ªói: %s" ,error)
    stop_event.set()

def on_close():
    logging.info("üîí K·∫øt n·ªëi ƒë√£ ƒë√≥ng")
    stop_event.set()

def on_open():
    logging.info("üîì K·∫øt n·ªëi ƒë√£ m·ªü")

# -------------------- Main streaming loop --------------------
def stream():
    global last_msg_time
    while True:
        try:
            stop_event.clear()
            mm = MarketDataStream(config, MarketDataClient(config))
            last_msg_time = time.time()

            mm.start(on_message, on_error, "X:ALL")

            while is_trading_time() and not stop_event.is_set():
                time.sleep(1)
                if time.time() - last_msg_time > 10:
                    logging.warning("‚ö†Ô∏è Kh√¥ng c√≥ data m·ªõi trong 10s, reconnect...")
                    stop_event.set()

        except Exception as e:
            logging.exception("‚ö†Ô∏è L·ªói trong stream():")
        finally:
            try:
                mm.stop()
                logging.info("üõë ƒê√£ d·ª´ng stream c≈© tr∆∞·ªõc khi reconnect")
            except Exception:
                pass

            logging.info("üîÑ Th·ª≠ k·∫øt n·ªëi l·∫°i sau 5 gi√¢y...")
            time.sleep(5)

if __name__ == "__main__":
    stream()

